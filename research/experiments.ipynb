{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name aari1995/German_Semantic_STS_V2. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import weaviate\n",
    "import tiktoken\n",
    "from llama_index.vector_stores.weaviate import WeaviateVectorStore\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.core import StorageContext, VectorStoreIndex, get_response_synthesizer, Settings\n",
    "from llama_index.llms.anthropic import Anthropic\n",
    "from llama_index.llms.groq import Groq\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.callbacks import CallbackManager, TokenCountingHandler\n",
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"Du bist ein hilfreicher deutscher Assistent für junge Eltern, der Informationen aus Foren sammelt, um Eltern bei der Beantwortung von Fragen über ihre Kinder zu helfen.\n",
    "\n",
    "            Verwende die folgenden Konversationen aus Elternforen, um den Nutzer über ein bestimmtes Thema zu helfen. Jede Zeile beginnt mit dem Namen des Benutzers, gefolgt von \":\" und dann dem Kommentar, zum Beispiel so: \"John: Bei mir ist es genauso.\"\n",
    "            Verschiedene Konversationen können sich auf dasselbe Thema beziehen.\n",
    "            <conversations>\n",
    "            {context_str}\n",
    "            </conversations>\n",
    "            \n",
    "            Wenn du die Unterhaltungen im Forum zitierst, gib bitte den Benutzernamen in deiner Antwort an. Hier sind Beispielw in <example> Tags:\n",
    "            <example>\n",
    "            Viele Nutzer sagen dass es normal ist Kinder nachts zu stillen. Cari234 sagt, z.B, dass sie täglich überfordert ist. Lomo2 hat gleiche Erfahrungen.\n",
    "            </example>\n",
    "            <example>\n",
    "            Die Konversationen beinhalten keine Hinweise ob es normal ist, dass Kinder nachts Wachfenster haben.\n",
    "            </example>\n",
    "\n",
    "            Hier ist deine Aufgabe: Welche relevanten Informationen kannst du aus den oben genannten Gesprächen zu diesem Thema entnehmen? Das Thema ist unten in <question>-Tags:\n",
    "            <question>\n",
    "            {query_str}\n",
    "            </question>\n",
    "\n",
    "            Um deine Aufgabe zu erledigen, gehe die folgenden Schritte durch:\n",
    "            1. Erstelle eine umfassende Zusammenfassung für jede Konversation in <conversation> Tags oben. Die Zusammenfassungen sollte alle wichtigen Punkte und Hauptgedanken des Originaltextes die sich auf diesem Aufgabe Thema beziehen abdecken und gleichzeitig die Informationen in einem prägnanten und leicht verständlichen Format zusammenfassen.\n",
    "            Achte bitte darauf, dass die Zusammenfassung die Usernamen, relevante Details und Beispiele enthält, die die Hauptgedanken unterstützen, und vermeide unnötige Informationen oder Wiederholungen.\n",
    "            2. Erledige deine Aufgabe auf der Grundlage der Zusammenfassungen von Schritt 1. Füge alle relevanten Informationen, Details und Beispiele ein die aus der Zusammenfassungen rauskommen und sich auf diesem Thema beziehen. Behalte die Antwort auf maximal 5 Sätze.\n",
    "\n",
    "            Wenn du die Aufgabe erledigst, nenn bitte konkrete Beispiele und Tipps aus den Forendiskussionen und verallgemeinere die Details nicht. Wenn du die Antwort nicht weißt, sag einfach, dass du es nicht weißt.\n",
    "            Fang deine Antwort mit \"Das sagen andere Nutzer dazu:\" an. Danach, gib die Zusammenfassungen von Schritt 1 aus als Bulletpoint-Liste aus. Für jede Konversation soll es ein Bulletpoint geben. Gib dann deine zusammenfassende Antwort gemäß Schritt 2 in eine neue Zeile ein.\n",
    "            Hier sind Beispiele wie deine Antworten formattiert werden sollen, in <answer-example>-Tags:\n",
    "\n",
    "            <answer-example>\n",
    "            Das sagen andere Nutzer dazu:\n",
    "            - jomda erklärt, dass Babys manchmal schreien, wenn ältere Geschwister versorgt werden müssen oder wenn das Baby nachts wach wird, weil der Betreuer kurz etwas erledigen muss.\n",
    "            - Mami83 berichtet, dass ihr Baby auch Phasen hatte, in denen es sehr unruhig war und häufig nachts aufwachte. Caro34 bestätigt.\n",
    "\n",
    "            Das sagen die Nutzer zusammengefasst: Häufiges nächtliches Aufwachen und Unruhe sind bei Babys oft normal und hängen mit deren Entwicklung und Bedürfnissen zusammen. Die Situation kann vorübergehend sehr herausfordernd sein, aber die Eltern müssen durchhalten, da es mit der Zeit wieder besser wird.\n",
    "            </answer-example>\n",
    "            <answer-example>\n",
    "            Das sagen andere Nutzer dazu:\n",
    "            - bilbo45 sagt, dass solche schwierigen Phasen normal sind und immer wieder kommen können, da sich Babys ständig weiterentwickeln. Sie ermutigt, durchzuhalten, da es mit der Zeit besser wird.\n",
    "            - Micebwn beschreibt, dass ihr 9 Monate altes Baby seit Tagen nachts weinend aufwacht.\n",
    "\n",
    "            Aus den Gesprächen geht hervor, dass bei den meisten Kindern dieser spezielle Test mit schwarzen und weißen Punkten, bei denen das Kind etwas Bestimmtes erkennen und zeigen soll, im Alter von 11 Monaten noch nicht funktioniert. Die Eltern berichten, dass ihre Kinder stattdessen eher versuchen, mit den Fingern in den Mund der Ärzte zu kommen oder generell eher an der Untersuchung interessiert sind als an dem Test.\n",
    "            </answer-example>    \n",
    "\n",
    "            Erledige jetzt bitte deine Aufgabe bezüglich des Themas von oben.\n",
    "            \"\"\"\n",
    "EMBEDDING_MODEL = 'aari1995/German_Semantic_STS_V2'\n",
    "# MAX_TOKENS = 4000\n",
    "\n",
    "groq_api_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "\n",
    "llm =  Groq(\n",
    "            model=\"llama3-70b-8192\",\n",
    "            api_key=groq_api_key,\n",
    "            # max_tokens=MAX_TOKENS\n",
    "        )\n",
    "# llm =  Groq(\n",
    "#             model=\"mixtral-8x7b-32768\",\n",
    "#             api_key=groq_api_key,\n",
    "#         )\n",
    "# llm = Anthropic(model=\"claude-3-haiku-20240307\")\n",
    "embedding_model = HuggingFaceEmbedding(model_name=EMBEDDING_MODEL)\n",
    "# Settings.tokenizer = tokenizer\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embedding_model\n",
    "# token_counter = TokenCountingHandler(\n",
    "#     tokenizer=tiktoken.encoding_for_model(\"llama3-70b-8192\").encode\n",
    "# )\n",
    "# Settings.callback_manager = CallbackManager([token_counter])\n",
    "\n",
    "client = weaviate.Client(\"http://localhost:8080\")\n",
    "vector_store = WeaviateVectorStore(weaviate_client = client, embed_model=embedding_model, index_name=\"BabyForum\")\n",
    "storage_context = StorageContext.from_defaults(vector_store = vector_store)\n",
    "index = VectorStoreIndex.from_vector_store(vector_store=vector_store, storage_context=storage_context)\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=10,\n",
    "    # filters=filters,\n",
    ")\n",
    "response_synthesizer = get_response_synthesizer(llm = llm, response_mode=\"simple_summarize\")\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.75)],\n",
    ")\n",
    "\n",
    "qa_prompt_tmpl = PromptTemplate(PROMPT_TEMPLATE)\n",
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:text_qa_template\": qa_prompt_tmpl}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Calculated available context size -1200 was not non-negative.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m answer1 \u001b[38;5;241m=\u001b[39m query_engine\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKind hat ein Stein verschluckt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/urbia-rag/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:274\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[1;32m    271\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[1;32m    272\u001b[0m )\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[0;32m~/miniconda3/envs/urbia-rag/lib/python3.12/site-packages/llama_index/core/base/base_query_engine.py:53\u001b[0m, in \u001b[0;36mBaseQueryEngine.query\u001b[0;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(str_or_query_bundle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     52\u001b[0m         str_or_query_bundle \u001b[38;5;241m=\u001b[39m QueryBundle(str_or_query_bundle)\n\u001b[0;32m---> 53\u001b[0m     query_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query(str_or_query_bundle)\n\u001b[1;32m     54\u001b[0m dispatch_event(QueryEndEvent())\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m query_result\n",
      "File \u001b[0;32m~/miniconda3/envs/urbia-rag/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:274\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[1;32m    271\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[1;32m    272\u001b[0m )\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[0;32m~/miniconda3/envs/urbia-rag/lib/python3.12/site-packages/llama_index/core/query_engine/retriever_query_engine.py:190\u001b[0m, in \u001b[0;36mRetrieverQueryEngine._query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m    187\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mQUERY, payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query_bundle\u001b[38;5;241m.\u001b[39mquery_str}\n\u001b[1;32m    188\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m query_event:\n\u001b[1;32m    189\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve(query_bundle)\n\u001b[0;32m--> 190\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_synthesizer\u001b[38;5;241m.\u001b[39msynthesize(\n\u001b[1;32m    191\u001b[0m         query\u001b[38;5;241m=\u001b[39mquery_bundle,\n\u001b[1;32m    192\u001b[0m         nodes\u001b[38;5;241m=\u001b[39mnodes,\n\u001b[1;32m    193\u001b[0m     )\n\u001b[1;32m    194\u001b[0m     query_event\u001b[38;5;241m.\u001b[39mon_end(payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mRESPONSE: response})\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/envs/urbia-rag/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:274\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[1;32m    271\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[1;32m    272\u001b[0m )\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[0;32m~/miniconda3/envs/urbia-rag/lib/python3.12/site-packages/llama_index/core/response_synthesizers/base.py:241\u001b[0m, in \u001b[0;36mBaseSynthesizer.synthesize\u001b[0;34m(self, query, nodes, additional_source_nodes, **response_kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m     query \u001b[38;5;241m=\u001b[39m QueryBundle(query_str\u001b[38;5;241m=\u001b[39mquery)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m    238\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mSYNTHESIZE,\n\u001b[1;32m    239\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query\u001b[38;5;241m.\u001b[39mquery_str},\n\u001b[1;32m    240\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[0;32m--> 241\u001b[0m     response_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_response(\n\u001b[1;32m    242\u001b[0m         query_str\u001b[38;5;241m=\u001b[39mquery\u001b[38;5;241m.\u001b[39mquery_str,\n\u001b[1;32m    243\u001b[0m         text_chunks\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m    244\u001b[0m             n\u001b[38;5;241m.\u001b[39mnode\u001b[38;5;241m.\u001b[39mget_content(metadata_mode\u001b[38;5;241m=\u001b[39mMetadataMode\u001b[38;5;241m.\u001b[39mLLM) \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m nodes\n\u001b[1;32m    245\u001b[0m         ],\n\u001b[1;32m    246\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kwargs,\n\u001b[1;32m    247\u001b[0m     )\n\u001b[1;32m    249\u001b[0m     additional_source_nodes \u001b[38;5;241m=\u001b[39m additional_source_nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m    250\u001b[0m     source_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(nodes) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(additional_source_nodes)\n",
      "File \u001b[0;32m~/miniconda3/envs/urbia-rag/lib/python3.12/site-packages/llama_index/core/response_synthesizers/simple_summarize.py:90\u001b[0m, in \u001b[0;36mSimpleSummarize.get_response\u001b[0;34m(self, query_str, text_chunks, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m text_qa_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_text_qa_template\u001b[38;5;241m.\u001b[39mpartial_format(query_str\u001b[38;5;241m=\u001b[39mquery_str)\n\u001b[1;32m     89\u001b[0m single_text_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(text_chunks)\n\u001b[0;32m---> 90\u001b[0m truncated_chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prompt_helper\u001b[38;5;241m.\u001b[39mtruncate(\n\u001b[1;32m     91\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mtext_qa_template,\n\u001b[1;32m     92\u001b[0m     text_chunks\u001b[38;5;241m=\u001b[39m[single_text_chunk],\n\u001b[1;32m     93\u001b[0m )\n\u001b[1;32m     95\u001b[0m response: RESPONSE_TEXT_TYPE\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_streaming:\n",
      "File \u001b[0;32m~/miniconda3/envs/urbia-rag/lib/python3.12/site-packages/llama_index/core/indices/prompt_helper.py:255\u001b[0m, in \u001b[0;36mPromptHelper.truncate\u001b[0;34m(self, prompt, text_chunks, padding, llm)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtruncate\u001b[39m(\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    249\u001b[0m     prompt: BasePromptTemplate,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    252\u001b[0m     llm: Optional[LLM] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    253\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    254\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Truncate text chunks to fit available context window.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m     text_splitter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_text_splitter_given_prompt(\n\u001b[1;32m    256\u001b[0m         prompt,\n\u001b[1;32m    257\u001b[0m         num_chunks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(text_chunks),\n\u001b[1;32m    258\u001b[0m         padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m    259\u001b[0m         llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[1;32m    260\u001b[0m     )\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [truncate_text(chunk, text_splitter) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m text_chunks]\n",
      "File \u001b[0;32m~/miniconda3/envs/urbia-rag/lib/python3.12/site-packages/llama_index/core/indices/prompt_helper.py:234\u001b[0m, in \u001b[0;36mPromptHelper.get_text_splitter_given_prompt\u001b[0;34m(self, prompt, num_chunks, padding, llm)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_text_splitter_given_prompt\u001b[39m(\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    226\u001b[0m     prompt: BasePromptTemplate,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    229\u001b[0m     llm: Optional[LLM] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    230\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TokenTextSplitter:\n\u001b[1;32m    231\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get text splitter configured to maximally pack available context window,\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m    taking into account of given prompt, and desired number of chunks.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m     chunk_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_available_chunk_size(\n\u001b[1;32m    235\u001b[0m         prompt, num_chunks, padding\u001b[38;5;241m=\u001b[39mpadding, llm\u001b[38;5;241m=\u001b[39mllm\n\u001b[1;32m    236\u001b[0m     )\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunk_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChunk size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not positive.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/urbia-rag/lib/python3.12/site-packages/llama_index/core/indices/prompt_helper.py:218\u001b[0m, in \u001b[0;36mPromptHelper._get_available_chunk_size\u001b[0;34m(self, prompt, num_chunks, padding, llm)\u001b[0m\n\u001b[1;32m    215\u001b[0m     prompt_str \u001b[38;5;241m=\u001b[39m get_empty_prompt_txt(prompt)\n\u001b[1;32m    216\u001b[0m     num_prompt_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_token_counter\u001b[38;5;241m.\u001b[39mget_string_tokens(prompt_str)\n\u001b[0;32m--> 218\u001b[0m available_context_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_available_context_size(num_prompt_tokens)\n\u001b[1;32m    219\u001b[0m result \u001b[38;5;241m=\u001b[39m available_context_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_chunks \u001b[38;5;241m-\u001b[39m padding\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_size_limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/urbia-rag/lib/python3.12/site-packages/llama_index/core/indices/prompt_helper.py:150\u001b[0m, in \u001b[0;36mPromptHelper._get_available_context_size\u001b[0;34m(self, num_prompt_tokens)\u001b[0m\n\u001b[1;32m    148\u001b[0m context_size_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_window \u001b[38;5;241m-\u001b[39m num_prompt_tokens \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_output\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context_size_tokens \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculated available context size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext_size_tokens\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m not non-negative.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    153\u001b[0m     )\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m context_size_tokens\n",
      "\u001b[0;31mValueError\u001b[0m: Calculated available context size -1200 was not non-negative."
     ]
    }
   ],
   "source": [
    "answer1 = query_engine.query(\"Kind hat ein Stein verschluckt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source #0 has score 0.80401653:\n",
      "lizzywithD: danke dir! das mit dem im eigenen zimmer schlafen überlege ich mir ständig aber ich kann\n",
      "Source #1 has score 0.79711473:\n",
      "SteMatz: Schlichtweg ... JA. Meine Maus schläft auch durch, leider sehr unruhig und ich werde bei je\n",
      "Source #2 has score 0.79370987:\n",
      "Mami823: War bei uns genauso. Als er ca. 3,5 Monate alt war, habe ich mein Baby nicht wiedererkannt.\n",
      "Source #3 has score 0.79095107:\n",
      "Sonnenschein729: Hallo 🙋🏼‍♀️ mein Sohn wird nächste Woche erst fünf Monate alt. Liest sich als wäre \n",
      "Source #4 has score 0.79071355:\n",
      "Thema:ist das noch normal?\n",
      "lizzywithD: hallo community\n",
      "beitrag nr. 4 in kürzerer zeit. \n",
      "thema: babys\n",
      "Source #5 has score 0.78898525:\n",
      "Thema:Baby macht in der Nacht Situps\n",
      "LiNo33: Hallo zusammen,\n",
      "mein kleiner schläft seit einigen Woche\n",
      "Source #6 has score 0.78773314:\n",
      "Thema:Baby 21 Wochen alt\n",
      "Vanni9: Hallo zusammen, \n",
      "Unser kleine ist heute 21 Wochen alt. Seit circa 2\n",
      "Source #7 has score 0.7872818699999999:\n",
      "Tanja.SoSo: Hallöchen und ein frohes neues Jahr euch allen! 🍀🎆\n",
      "Wahnsinn, wie schnell die Zeit doch r\n",
      "Source #8 has score 0.78485173:\n",
      "Jolana: Ich gehör auch zur Kategorie \"klingt wie bei uns und normal\". Der Kleine (4,5 Monate) schläf\n",
      "Source #9 has score 0.784706:\n",
      "Thema:Baby sehr zappelig unruhig\n",
      "Nanus: Hallo muttis\n",
      "Meine tochter fast 5 moange alt ist sehr zappel\n",
      "Das sagen andere Nutzer dazu:\n",
      "\n",
      "* LizzywithD beschreibt, dass ihr Baby stündlich aufwacht und sie sich Sorgen macht, ob ihr Baby eine Schlafstörung hat.\n",
      "* Kuddelmuddel erzählt, dass ihr Sohn Junior schnarchte und deshalb nicht im Familienbett schlafen konnte. Sie bemerkte, dass er besser schlief, wenn er nicht mehr neben ihnen lag.\n",
      "* Elly0109 teilt mit, dass ihre Tochter früher zwischen 3:30 und 4 Uhr aufwachte und dass Kinder unterschiedlich sind und sich ändern.\n",
      "* SteMatz sagt, dass ihr Kind auch unruhig schläft und sie oft geweckt wird.\n",
      "* Blabliblu meint, dass man sich an den Schlafmangel gewöhnt und dass es wichtig ist, den richtigen Schlafzyklus zu finden.\n",
      "* Muriel erklärt, dass es wichtig ist, den richtigen Schlafzyklus zu finden und dass die Hormone auch eine Rolle spielen.\n",
      "* Lattemachiatto teilt mit, dass sie müde war, wenn ihr Baby weiter weg von ihr schlief und dass sie besser schlief, wenn das Baby direkt neben ihr lag.\n",
      "* Mami823 erzählt, dass ihr Baby auch sehr unruhig war und dass sie es konsequent alle 2 Stunden zum Schlafen gebracht hat.\n",
      "* Sonnenschein729 beschreibt, dass ihr Sohn auch Probleme hatte, einzuschlafen, und dass er gerne sitzt und seine Bauchmuskeln testet.\n",
      "\n",
      "Das sagen die Nutzer zusammengefasst: Es ist normal, dass Babys stündlich aufwachen und dass es wichtig ist, den richtigen Schlafzyklus zu finden. Die Eltern müssen durchhalten, da es mit der Zeit wieder besser wird.\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for source in answer1.source_nodes:\n",
    "    print(f\"Source #{ count } has score {source.score}:\\n{source.text[:100]}\")\n",
    "    count += 1\n",
    "\n",
    "print(answer1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urbia-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
