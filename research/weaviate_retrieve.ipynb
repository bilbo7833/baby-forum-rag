{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Start Docker Service\n",
    "2. Start Docker configuration in `docker-compose.yaml` with `docker compose up`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import weaviate\n",
    "from llama_index.vector_stores.weaviate import WeaviateVectorStore\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.core import StorageContext, VectorStoreIndex, get_response_synthesizer, Settings\n",
    "from llama_index.llms.anthropic import Anthropic\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "\n",
    "\n",
    "EMBEDDING_MODEL = 'aari1995/German_Semantic_STS_V2'\n",
    "\n",
    "def save_file(file, text):\n",
    "    f = open(file, \"w\")\n",
    "    f.write(text)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"\"\n",
    "tokenizer = Anthropic().tokenizer\n",
    "llm = Anthropic(model=\"claude-3-haiku-20240307\")\n",
    "embedding_model = HuggingFaceEmbedding(model_name=EMBEDDING_MODEL)\n",
    "Settings.tokenizer = tokenizer\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = weaviate.Client(\"http://localhost:8080\")\n",
    "print(client.get_meta())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = WeaviateVectorStore(weaviate_client = client, embed_model=embedding_model, llm=llm, index_name=\"BabyForum\")\n",
    "storage_context = StorageContext.from_defaults(vector_store = vector_store)\n",
    "index = VectorStoreIndex.from_vector_store(vector_store=vector_store, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=10,\n",
    "    llm=llm\n",
    ")\n",
    "response_synthesizer = get_response_synthesizer(response_mode=\"simple_summarize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    # node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.8)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Markdown, display\n",
    "# def display_prompt_dict(prompts_dict):\n",
    "#     for k, p in prompts_dict.items():\n",
    "#         text_md = f\"**Prompt Key**: {k}<br>\" f\"**Text:** <br>\"\n",
    "#         display(Markdown(text_md))\n",
    "#         print(p.get_template())\n",
    "#         display(Markdown(\"<br><br>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompts_dict = query_engine.get_prompts()\n",
    "# display_prompt_dict(prompts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "PROMPT_TEMPLATE = \"\"\"Du bist ein hilfreicher deutscher Assistent für junge Eltern, der Informationen aus Foren sammelt, um Eltern bei der Beantwortung von Fragen über ihre Kinder zu helfen.\n",
    "\n",
    "            Verwende die folgenden Konversationen aus Elternforen, um den Nutzer über ein bestimmtes Thema zu helfen. Jede Zeile beginnt mit dem Namen des Benutzers, gefolgt von \":\" und dann dem Kommentar, zum Beispiel so: \"John: Bei mir ist es genauso.\"\n",
    "            Verschiedene Konversationen können sich auf dasselbe Thema beziehen.\n",
    "            <conversations>\n",
    "            {context_str}\n",
    "            </conversations>\n",
    "            \n",
    "            Wenn du die Unterhaltungen im Forum zitierst, gib bitte den Benutzernamen in deiner Antwort an. Hier sind Beispielw in <example> Tags:\n",
    "            <example>\n",
    "            Viele Nutzer sagen dass es normal ist Kinder nachts zu stillen. Cari234 sagt, z.B, dass sie täglich überfordert ist. Lomo2 hat gleiche Erfahrungen.\n",
    "            </example>\n",
    "            <example>\n",
    "            Die Konversationen beinhalten keine Hinweise ob es normal ist, dass Kinder nachts Wachfenster haben.\n",
    "            </example>\n",
    "\n",
    "            Hier ist deine Aufgabe: Welche relevanten Informationen kannst du aus den oben genannten Gesprächen zu diesem Thema entnehmen? Das Thema ist unten in <question>-Tags:\n",
    "            <question>\n",
    "            {query_str}\n",
    "            </question>\n",
    "\n",
    "            Um deine Aufgabe zu erledigen, gehe die folgenden Schritte durch:\n",
    "            1. Erstelle eine umfassende Zusammenfassung für jede Konversation in <conversation> Tags oben. Die Zusammenfassungen sollte alle wichtigen Punkte und Hauptgedanken des Originaltextes die sich auf diesem Aufgabe Thema beziehen abdecken und gleichzeitig die Informationen in einem prägnanten und leicht verständlichen Format zusammenfassen.\n",
    "            Achte bitte darauf, dass die Zusammenfassung die Usernamen, relevante Details und Beispiele enthält, die die Hauptgedanken unterstützen, und vermeide unnötige Informationen oder Wiederholungen.\n",
    "            2. Erledige deine Aufgabe auf der Grundlage der Zusammenfassungen von Schritt 1. Füge alle relevanten Informationen, Details und Beispiele ein die aus der Zusammenfassungen rauskommen und sich auf diesem Thema beziehen. Behalte die Antwort auf maximal 5 Sätze.\n",
    "\n",
    "            Wenn du die Aufgabe erledigst, nenn bitte konkrete Beispiele und Tipps aus den Forendiskussionen und verallgemeinere die Details nicht. Wenn du die Antwort nicht weißt, sag einfach, dass du es nicht weißt.\n",
    "            Fang deine Antwort mit \"Das sagen andere Nutzer dazu:\" an. Danach, gib die Zusammenfassungen von Schritt 1 aus als Bulletpoint-Liste aus. Für jede Konversation soll es ein Bulletpoint geben. Gib dann deine zusammenfassende Antwort gemäß Schritt 2 in eine neue Zeile ein.\n",
    "            Hier sind Beispiele wie deine Antworten formattiert werden sollen, in <answer-example>-Tags:\n",
    "\n",
    "            <answer-example>\n",
    "            Das sagen andere Nutzer dazu:\n",
    "            - jomda erklärt, dass Babys manchmal schreien, wenn ältere Geschwister versorgt werden müssen oder wenn das Baby nachts wach wird, weil der Betreuer kurz etwas erledigen muss.\n",
    "            - Mami83 berichtet, dass ihr Baby auch Phasen hatte, in denen es sehr unruhig war und häufig nachts aufwachte. Caro34 bestätigt.\n",
    "\n",
    "            Das sagen die Nutzer zusammengefasst: Häufiges nächtliches Aufwachen und Unruhe sind bei Babys oft normal und hängen mit deren Entwicklung und Bedürfnissen zusammen. Die Situation kann vorübergehend sehr herausfordernd sein, aber die Eltern müssen durchhalten, da es mit der Zeit wieder besser wird.\n",
    "            </answer-example>\n",
    "            <answer-example>\n",
    "            Das sagen andere Nutzer dazu:\n",
    "            - bilbo45 sagt, dass solche schwierigen Phasen normal sind und immer wieder kommen können, da sich Babys ständig weiterentwickeln. Sie ermutigt, durchzuhalten, da es mit der Zeit besser wird.\n",
    "            - Micebwn beschreibt, dass ihr 9 Monate altes Baby seit Tagen nachts weinend aufwacht.\n",
    "\n",
    "            Aus den Gesprächen geht hervor, dass bei den meisten Kindern dieser spezielle Test mit schwarzen und weißen Punkten, bei denen das Kind etwas Bestimmtes erkennen und zeigen soll, im Alter von 11 Monaten noch nicht funktioniert. Die Eltern berichten, dass ihre Kinder stattdessen eher versuchen, mit den Fingern in den Mund der Ärzte zu kommen oder generell eher an der Untersuchung interessiert sind als an dem Test.\n",
    "            </answer-example>    \n",
    "\n",
    "            Erledige jetzt bitte deine Aufgabe bezüglich des Themas von oben.\n",
    "            \"\"\"\n",
    "\n",
    "qa_prompt_tmpl = PromptTemplate(PROMPT_TEMPLATE)\n",
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:text_qa_template\": qa_prompt_tmpl}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompts_dict = query_engine.get_prompts()\n",
    "# display_prompt_dict(prompts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer1 = query_engine.query(\"Kind wacht stündlich auf\")\n",
    "for n in answer1.source_nodes:\n",
    "    print(f\"Node {n.node_id} with similarity score {n.score}:\\n{n.text}\\n\\n\\n\")\n",
    "print(answer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer2 = query_engine.query(\"Wer kümmert sich um das Kind nachts?\")\n",
    "for n in answer2.source_nodes:\n",
    "    print(f\"Node {n.node_id} with similarity score {n.score}:\\n{n.text}\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "answer3 = query_engine.query(\"Wann darf man mit kind ins Tropical Island?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(str(answer3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.environ.get('OPENAI_API_KEY'))\n",
    "print(os.environ.get('ANTHROPIC_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if client.collections.exists(\"ForumPost\"):\n",
    "#     client.collections.delete(\"ForumPost\")\n",
    "# client.collections.create(\n",
    "#     \"ForumPost\",\n",
    "#     vectorizer_config=Configure.Vectorizer.text2vec_transformers(),\n",
    "#     generative_config=Configure.Generative.openai(model='gpt-3.5-turbo'),\n",
    "#     properties=[\n",
    "#         Property(name=\"body\", data_type=DataType.TEXT),\n",
    "#     ]\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post1 = {'body': \"Das ist ein langes Post über weinenende Kinder\"}\n",
    "# post2 = {'body': \"Mein Baby isst nichts mehr tagsüber\"}\n",
    "# post3 = {'body': \"Kind wacht Nachts weinend auf und schreit\"}\n",
    "# posts = client.collections.get(\"ForumPost\")\n",
    "# posts.data.insert(post1)\n",
    "# posts.data.insert_many([post2, post3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posts = client.collections.get(\"ForumPost\")\n",
    "# for item in posts.iterator(include_vector=True):\n",
    "#     print(item.properties)\n",
    "#     print(item.vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = posts.query.near_text(\n",
    "#         query=\"Baby weint\",\n",
    "#         return_metadata=wvc.query.MetadataQuery(distance=True),\n",
    "#         limit=2\n",
    "#     )\n",
    "\n",
    "# for o in response.objects:\n",
    "#     print(o.properties)\n",
    "#     print(o.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = posts.query.hybrid(\n",
    "#         query=\"Baby weint\",\n",
    "#         return_metadata=wvc.query.MetadataQuery(distance=True, score=True, explain_score=True),\n",
    "#         alpha=0.75,\n",
    "#         limit=3\n",
    "#     )\n",
    "\n",
    "# for o in response.objects:\n",
    "#     print(o.properties)\n",
    "#     print(o.metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urbia-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
